================================================================================
QUERY ANALYSIS - OLTP Performance Bottlenecks
================================================================================
Healthcare Analytics Lab: OLTP to Star Schema
Part 2: Find the Performance Problem

This document analyzes 4 business questions using the normalized OLTP schema,
identifying performance bottlenecks that the star schema will address.

================================================================================
QUESTION 1: Monthly Encounters by Specialty
================================================================================

BUSINESS NEED:
For each month and specialty, show total encounters and unique patients 
by encounter type.

--------------------------------------------------------------------------------
SQL QUERY:
--------------------------------------------------------------------------------

SELECT 
    YEAR(e.encounter_date) AS year,
    MONTH(e.encounter_date) AS month,
    s.specialty_name,
    e.encounter_type,
    COUNT(*) AS total_encounters,
    COUNT(DISTINCT e.patient_id) AS unique_patients
FROM encounters e
JOIN providers p ON e.provider_id = p.provider_id
JOIN specialties s ON p.specialty_id = s.specialty_id
GROUP BY 
    YEAR(e.encounter_date),
    MONTH(e.encounter_date),
    s.specialty_name,
    e.encounter_type
ORDER BY year, month, specialty_name;

--------------------------------------------------------------------------------
SCHEMA ANALYSIS:
--------------------------------------------------------------------------------

Tables joined:
  1. encounters (central fact)
  2. providers (to get specialty_id)
  3. specialties (to get specialty_name)

Number of joins: 2

Join chain:
  encounters → providers → specialties

--------------------------------------------------------------------------------
PERFORMANCE:
--------------------------------------------------------------------------------

Estimated execution time: ~1.2 seconds (with 10,000 rows per table)

Estimated rows scanned:
  - encounters: 10,000 rows
  - providers: 10,000 lookups
  - specialties: 10,000 lookups

--------------------------------------------------------------------------------
BOTTLENECK IDENTIFIED:
--------------------------------------------------------------------------------

1. **JOIN Chain Overhead**: Every encounter requires traversing through the 
   providers table just to get the specialty_id, then another lookup to get 
   the specialty_name. This indirect relationship adds latency.

2. **GROUP BY on Multiple Columns**: Grouping by year, month, specialty, and 
   encounter_type requires sorting and aggregating across many dimensions.

3. **Date Function Overhead**: YEAR() and MONTH() functions are computed for 
   every row, preventing index usage on encounter_date.

4. **No Pre-Computed Aggregates**: Every query recalculates counts from scratch.


================================================================================
QUESTION 2: Top Diagnosis-Procedure Pairs
================================================================================

BUSINESS NEED:
What are the most common diagnosis-procedure combinations? 
Show the ICD code, procedure code, and encounter count.

--------------------------------------------------------------------------------
SQL QUERY:
--------------------------------------------------------------------------------

SELECT 
    d.icd10_code,
    d.icd10_description,
    p.cpt_code,
    p.cpt_description,
    COUNT(DISTINCT ed.encounter_id) AS encounter_count
FROM encounter_diagnoses ed
JOIN diagnoses d ON ed.diagnosis_id = d.diagnosis_id
JOIN encounter_procedures ep ON ed.encounter_id = ep.encounter_id
JOIN procedures p ON ep.procedure_id = p.procedure_id
GROUP BY 
    d.icd10_code,
    d.icd10_description,
    p.cpt_code,
    p.cpt_description
ORDER BY encounter_count DESC
LIMIT 20;

--------------------------------------------------------------------------------
SCHEMA ANALYSIS:
--------------------------------------------------------------------------------

Tables joined:
  1. encounter_diagnoses (junction table)
  2. diagnoses (to get ICD codes)
  3. encounter_procedures (junction table, joined on encounter_id)
  4. procedures (to get CPT codes)

Number of joins: 3 (plus implicit self-join logic)

Join chain:
  encounter_diagnoses → diagnoses
        ↓
  encounter_procedures → procedures
  (joined via encounter_id)

--------------------------------------------------------------------------------
PERFORMANCE:
--------------------------------------------------------------------------------

Estimated execution time: ~3.5 seconds (with 10,000 rows per table)

Estimated rows scanned:
  - encounter_diagnoses: 10,000 rows
  - diagnoses: 10,000 lookups
  - encounter_procedures: up to 10,000 × 10,000 in worst case (Cartesian potential)
  - procedures: many lookups

--------------------------------------------------------------------------------
BOTTLENECK IDENTIFIED:
--------------------------------------------------------------------------------

1. **Row Explosion (Cartesian Product Risk)**: Joining two junction tables 
   (encounter_diagnoses and encounter_procedures) on encounter_id can cause 
   massive row multiplication. If an encounter has 3 diagnoses and 2 procedures, 
   that's 6 rows per encounter.

2. **Two Independent Junction Tables**: The diagnosis-procedure relationship 
   doesn't exist directly; we must go through the encounter as a bridge, 
   which is inefficient.

3. **COUNT(DISTINCT)**: Requires deduplication overhead to avoid counting 
   the same encounter multiple times.

4. **No Direct Relationship**: There's no table that directly links diagnoses 
   to procedures, forcing a multi-step join through encounters.


================================================================================
QUESTION 3: 30-Day Readmission Rate
================================================================================

BUSINESS NEED:
Which specialty has the highest readmission rate?
(Definition: inpatient discharge, then return within 30 days)

--------------------------------------------------------------------------------
SQL QUERY:
--------------------------------------------------------------------------------

WITH inpatient_discharges AS (
    SELECT 
        e.encounter_id,
        e.patient_id,
        e.discharge_date,
        p.specialty_id
    FROM encounters e
    JOIN providers pr ON e.provider_id = pr.provider_id
    JOIN providers p ON pr.provider_id = p.provider_id
    WHERE e.encounter_type = 'Inpatient'
),
readmissions AS (
    SELECT 
        d.encounter_id AS initial_encounter,
        d.specialty_id,
        e2.encounter_id AS readmit_encounter
    FROM inpatient_discharges d
    JOIN encounters e2 ON d.patient_id = e2.patient_id
        AND e2.encounter_date > d.discharge_date
        AND e2.encounter_date <= DATE_ADD(d.discharge_date, INTERVAL 30 DAY)
        AND e2.encounter_type = 'Inpatient'
)
SELECT 
    s.specialty_name,
    COUNT(DISTINCT d.encounter_id) AS total_discharges,
    COUNT(DISTINCT r.initial_encounter) AS readmissions,
    ROUND(
        COUNT(DISTINCT r.initial_encounter) * 100.0 / 
        NULLIF(COUNT(DISTINCT d.encounter_id), 0), 
        2
    ) AS readmission_rate_pct
FROM inpatient_discharges d
LEFT JOIN readmissions r ON d.encounter_id = r.initial_encounter
JOIN specialties s ON d.specialty_id = s.specialty_id
GROUP BY s.specialty_name
ORDER BY readmission_rate_pct DESC;

--------------------------------------------------------------------------------
SCHEMA ANALYSIS:
--------------------------------------------------------------------------------

Tables joined:
  1. encounters (self-join for readmission detection)
  2. providers (to get specialty)
  3. specialties (to get specialty name)

Number of joins: 3 + self-join

Join chain:
  encounters (initial) → providers → specialties
        ↓ (self-join on patient_id + date logic)
  encounters (readmission)

--------------------------------------------------------------------------------
PERFORMANCE:
--------------------------------------------------------------------------------

Estimated execution time: ~5.0+ seconds (with 10,000 rows per table)

Estimated rows scanned:
  - encounters: 10,000 rows (filtered for Inpatient)
  - Self-join: potentially 10,000 × 10,000 comparisons
  - providers/specialties: additional lookups

--------------------------------------------------------------------------------
BOTTLENECK IDENTIFIED:
--------------------------------------------------------------------------------

1. **Self-Join on Large Table**: The encounters table must be joined with 
   itself to compare discharge dates with subsequent admission dates. This 
   is computationally expensive: O(n²) in the worst case.

2. **Date Range Comparison**: The 30-day window calculation 
   (DATE_ADD(discharge_date, INTERVAL 30 DAY)) must be computed for every 
   potential pair, preventing efficient index usage.

3. **No Pre-Computed Readmission Flag**: Each query must recalculate whether 
   an encounter is a readmission from scratch.

4. **Complex CTE Logic**: The query requires multiple CTEs (Common Table 
   Expressions) which create intermediate result sets that consume memory.


================================================================================
QUESTION 4: Revenue by Specialty & Month
================================================================================

BUSINESS NEED:
Total allowed amounts by specialty and month. 
Which specialties generate the most revenue?

--------------------------------------------------------------------------------
SQL QUERY:
--------------------------------------------------------------------------------

SELECT 
    YEAR(b.claim_date) AS year,
    MONTH(b.claim_date) AS month,
    s.specialty_name,
    COUNT(*) AS claim_count,
    SUM(b.claim_amount) AS total_claimed,
    SUM(b.allowed_amount) AS total_allowed,
    ROUND(AVG(b.allowed_amount), 2) AS avg_allowed
FROM billing b
JOIN encounters e ON b.encounter_id = e.encounter_id
JOIN providers p ON e.provider_id = p.provider_id
JOIN specialties s ON p.specialty_id = s.specialty_id
GROUP BY 
    YEAR(b.claim_date),
    MONTH(b.claim_date),
    s.specialty_name
ORDER BY year, month, total_allowed DESC;

--------------------------------------------------------------------------------
SCHEMA ANALYSIS:
--------------------------------------------------------------------------------

Tables joined:
  1. billing (source of revenue data)
  2. encounters (to link to provider)
  3. providers (to get specialty_id)
  4. specialties (to get specialty_name)

Number of joins: 3

Join chain:
  billing → encounters → providers → specialties

--------------------------------------------------------------------------------
PERFORMANCE:
--------------------------------------------------------------------------------

Estimated execution time: ~1.8 seconds (with 10,000 rows per table)

Estimated rows scanned:
  - billing: 10,000 rows
  - encounters: 10,000 lookups
  - providers: 10,000 lookups
  - specialties: 10,000 lookups

--------------------------------------------------------------------------------
BOTTLENECK IDENTIFIED:
--------------------------------------------------------------------------------

1. **Long JOIN Chain (4 Tables)**: To get from billing to specialty_name, 
   we must traverse through encounters → providers → specialties. This 
   is the longest chain in our queries.

2. **Aggregation Over Joins**: SUM and COUNT operations must process 
   joined data, which is larger than the base tables.

3. **Date Function Overhead**: YEAR() and MONTH() computed per row.

4. **No Denormalization**: Specialty information could be stored directly 
   with billing data to eliminate 2 of the 3 joins.

5. **Missing Pre-Aggregation**: Revenue totals are calculated fresh 
   every time instead of being stored in summary tables.


================================================================================
SUMMARY: OLTP PERFORMANCE ISSUES
================================================================================

| Query | Tables | Joins | Est. Time | Primary Bottleneck              |
|-------|--------|-------|-----------|----------------------------------|
| Q1    | 3      | 2     | ~1.2s     | Indirect specialty lookup        |
| Q2    | 4      | 3     | ~3.5s     | Junction table row explosion     |
| Q3    | 3      | 3+    | ~5.0s     | Self-join for readmission logic  |
| Q4    | 4      | 3     | ~1.8s     | Long JOIN chain (4 tables)       |

--------------------------------------------------------------------------------
ROOT CAUSES (Why OLTP is Slow for Analytics):
--------------------------------------------------------------------------------

1. **Normalization Overhead**: Data is split across many tables for integrity, 
   but this requires expensive JOINs for analytical queries.

2. **No Pre-Aggregation**: Every metric (counts, sums, averages) is calculated 
   from scratch on each query execution.

3. **Junction Table Complexity**: Many-to-many relationships require bridge 
   tables that can cause row explosion when joined.

4. **Missing Denormalization**: Frequently-accessed attributes (like specialty 
   name) are stored far from the data that needs them.

5. **No Time Dimension**: Date-based analysis requires function calls 
   (YEAR, MONTH) instead of looking up pre-computed values.

--------------------------------------------------------------------------------
SOLUTION: Star Schema
--------------------------------------------------------------------------------

The star schema addresses these issues by:

- **Denormalizing** dimension attributes directly into dimension tables
- **Pre-aggregating** common metrics in fact tables
- **Creating a time dimension** with pre-computed date parts
- **Reducing JOINs** from 3-4 to typically 1-2
- **Eliminating junction tables** by storing arrays or using bridge tables

================================================================================
